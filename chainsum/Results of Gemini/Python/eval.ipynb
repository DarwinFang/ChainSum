{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "current_dir = os.path.abspath('./../../../c2nl/eval')\n",
    "sys.path.append(current_dir)\n",
    "from rouge.rouge import Rouge\n",
    "from c2nl.eval.bleu import Bleu, nltk_corpus_bleu, corpus_bleu\n",
    "from meteor import Meteor\n",
    "import json\n",
    "from nltk.translate.meteor_score import meteor_score"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:22:24.803234Z",
     "start_time": "2024-07-31T11:22:24.012220Z"
    }
   },
   "id": "84ad0b19f927af"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "ref_file = './../test_data.json'\n",
    "ref = json.load(open(ref_file, 'r'))[:100]\n",
    "res_dict = dict()\n",
    "for d in ref:\n",
    "    res_dict[str(d['id'])] = [d['text']]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:22:25.942764Z",
     "start_time": "2024-07-31T11:22:25.874380Z"
    }
   },
   "id": "f4020d0d5f0e5e38"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "{'0': ['patch a resource  .'],\n '1': ['yield images of the laplacian pyramid formed by the input image  .'],\n '2': ['return a dict of the last function called for all minions  .'],\n '3': ['return list of paths that may contain available services  .'],\n '4': ['store a temporary file  .'],\n '5': ['create the output directory  .'],\n '6': ['get the integer value of a hexadecimal number  .'],\n '7': ['set the size of a finder window for folder to  .'],\n '8': ['backport of os  .'],\n '9': ['extract the filename if a url is an uploaded file  .'],\n '10': ['test setting up other volume source spaces  .'],\n '11': ['get latex preamble from rc  .'],\n '12': ['compute the generalized s-polynomial of f and g  .'],\n '13': ['deleted col of volume_type_projects converted  .'],\n '14': ['perform static object analysis on all python files in the project note that this might be really time consuming  .'],\n '15': ['return a shortened version string  .'],\n '16': ['modifies the main help menu to handle all registered help files  .'],\n '17': ['redirects to the specified location using the provided http_code  .'],\n '18': ['returns: - the first command when confirmation disabled; - none when ctrl+c pressed; - selected command  .'],\n '19': ['helper function to get linear projection or partialling out of variables endog variables are projected on exog variables parameters endog : ndarray array of variables where the effect of exog is partialled out  .'],\n '20': ['update composer dependencies for a directory  .'],\n '21': ['fetch targets and calculate the modules output on dataset  .'],\n '22': ['tests socket  .'],\n '23': ['get the path from the edge intersections  .'],\n '24': ['show a modeljob returns json when requested: {id  .'],\n '25': ['implements the c expression: condition ? true : false required to correctly interpret plural forms  .'],\n '26': ['returns true/false boolean depending on if botocore supports usage plan  .'],\n '27': ['return the load data that marks a specified jid  .'],\n '28': ['show runtime-editable configuration option  .'],\n '29': ['decorator to add a default structuring element to morphology functions  .'],\n '30': ['helper function to load a module while setting sys  .'],\n '31': ['move prepared osm data from temporary to permanent tables  .'],\n '32': ['returns object if t is of the form (1+exp(x))  .'],\n '33': ['round a to the nearest integer if that integer is within an epsilon of a  .'],\n '34': ['returns a string suitable for rfc 2822 compliant message-id  .'],\n '35': ['returns the linode id for a vm from the provided name  .'],\n '36': ['a wrapper around astropy  .'],\n '37': ['generate a csv file containing a summary of the xblock usage arguments: course_data : a list of course_data objects returns: nothing  .'],\n '38': ['regression test  .'],\n '39': ['returns true if the given estimator is a classifier  .'],\n '40': ['uses heuristics to guess whether the given file is text or binary  .'],\n '41': ['return the full url to the bootstrap css library default value: none this value is configurable  .'],\n '42': ['get objects of the type  .'],\n '43': ['expand shell variables of form $var and ${var}  .'],\n '44': ['get new repository  .'],\n '45': ['retrieves the block types from the provided xblock configuration json file arguments: xblock_json_file : the name of the xblock configuration file :return: set: a set of strings for all the types that are available in the configuration file  .'],\n '46': ['validates the inputs to the actions in a target  .'],\n '47': ['verify that *cert  (in decoded format as returned by sslsocket  .'],\n '48': ['compute f/a where f in gf(p)[x] and a in gf(p)  .'],\n '49': ['builds connection and search arguments  .'],\n '50': ['test the fitting method  .'],\n '51': ['this criteria is alerted if metrics data is completely missing at a timestamp  .'],\n '52': ['a helpful decorator which can switch the flag values temporarily  .'],\n '53': ['this method returns the entity of the element which link points to  .'],\n '54': ['bind cli arguments to a shell  .'],\n '55': ['from pep-318 URL#examples  .'],\n '56': ['checks if given contents begins with a pseudo-open-pgp-style block and  .'],\n '57': ['the directory that we check out our bundles to  .'],\n '58': ['get the top 10 keywords and their frequency scores ignores blacklisted words in stopwords  .'],\n '59': ['escape commas  .'],\n '60': ['cleanup after ci_build  .'],\n '61': ['encode a string using the standard base64 alphabet  .'],\n '62': ['import content from buf and return a python ast  .'],\n '63': ['merge dictionaries and apply function to combined values a key may occur in more than one dict  .'],\n '64': ['generates a list of colors based on a list of names  .'],\n '65': ['convert a multidict containing form data into a regular dict  .'],\n '66': ['check whether ldap authentication can be enabled  .'],\n '67': ['escape html in json value  .'],\n '68': ['sanitize a string  .'],\n '69': ['dummy implementation of thread  .'],\n '70': ['get summarize health this provides a summary of the health of the managed system  .'],\n '71': ['checks to see if the function is marked as not requiring authentication with the @unauthenticated decorator  .'],\n '72': ['used to instruct the agent to force a node into the left state  .'],\n '73': ['a convenience method for making a dist given just a name and version  .'],\n '74': ['install the pre-requisites for pip installation of the flocker client  .'],\n '75': ['compute polynomial pseudo-division of f and g  .'],\n '76': ['count occurrences of elements in this column sort by counts by default add sort=false keyword to avoid this behavior  .'],\n '77': ['return a list of tuples where s is the largest subset of elements that appear in pairs of sets given by sets and l is a list of tuples giving the indices of the pairs of sets in which those elements appeared  .'],\n '78': ['dump object to string  .'],\n '79': ['return a chunk from a file based on the data received  .'],\n '80': ['unconditionally skip a test  .'],\n '81': ['setup x10 switches over a mochad controller  .'],\n '82': ['test to ensure the custom boolean type correctly supports boolean conversion  .'],\n '83': ['set the default colormap to jet and apply to current image if any  .'],\n '84': ['the basic permission-checker only for player objects  .'],\n '85': ['unregister a previously registered hosting service  .'],\n '86': ['notice when hangup or timeout  .'],\n '87': ['convenience method for executing operating system commands  .'],\n '88': ['converts an sslerror  .'],\n '89': ['make every worker ignore keyboarinterrups since it will be handled by the parent process  .'],\n '90': ['rather basic  .'],\n '91': ['break text down into ngrams  .'],\n '92': ['convert an file system path to a uri portion that is suitable for inclusion in a url  .'],\n '93': ['format a string of python code  .'],\n '94': ['please note: this method must be called right before an expected alert window variables are page local and thus all changes are removed upon navigating to a new page in addition  .'],\n '95': ['convenience function for getting the text to use for a match when formatting  .'],\n '96': ['when calculating result rank  .'],\n '97': ['return an unused filename with the same extension as the specified path  .'],\n '98': ['return a random url-safe text string  .'],\n '99': ['sets up a logger for console output  .']}"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res_dict"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:22:37.311724Z",
     "start_time": "2024-07-31T11:22:37.290163Z"
    }
   },
   "id": "de6c5668dbb81018"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "def score(file, res_dict):\n",
    "    gpt_pred = json.load(open(file, 'r'))\n",
    "    rg = Rouge()\n",
    "    _, bleu, ind_bleu = corpus_bleu(gpt_pred, res_dict)\n",
    "    average_score, _ = rg.compute_score(gpt_pred, res_dict)\n",
    "    meteor = 0\n",
    "    for j in range(100):\n",
    "        t = \"{}\".format(j)\n",
    "        p = [w for w in gpt_pred[t][0].split()]\n",
    "        r = [w for w in res_dict[t][0].split()]\n",
    "        res = round(meteor_score([r], p), 4)\n",
    "        meteor += res\n",
    "    return bleu*100, average_score*100, meteor"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:23:26.478822Z",
     "start_time": "2024-07-31T11:23:26.461942Z"
    }
   },
   "id": "bd0f894ad6103575"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "for str in ['3.5','3.5pr','4o', '4opr']:\n",
    "    file = './gpt' + str + '.json'\n",
    "    print(str)\n",
    "    print(score(file, res_dict))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:23:16.722265Z",
     "start_time": "2024-07-31T11:23:16.710432Z"
    }
   },
   "id": "906805b8c94a7b09"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "gpt_pred = json.load(open('./gpt3.5.json', 'r'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:23:28.280193Z",
     "start_time": "2024-07-31T11:23:28.250567Z"
    }
   },
   "id": "b7a58f0251db26b8"
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "res_dict = {'0':[\"patch a resource .\"]}\n",
    "gpt_pred = {'0':[\"Updates .\"]}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:24:14.411163Z",
     "start_time": "2024-07-31T11:24:14.357760Z"
    }
   },
   "id": "c922b65de21590a1"
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [],
   "source": [
    "meteor_calculator = Meteor()\n",
    "meteor, _ = meteor_calculator.compute_score(gpt_pred, res_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:24:22.031540Z",
     "start_time": "2024-07-31T11:24:21.947796Z"
    }
   },
   "id": "7afd905c1002b4fb"
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "data": {
      "text/plain": "[85.22999999999999,\n 44.06,\n 17.24,\n 15.790000000000001,\n 89.63,\n 84.91,\n 11.76,\n 40.23,\n 19.61,\n 22.939999999999998,\n 53.73,\n 51.739999999999995,\n 74.72,\n 7.8100000000000005,\n 10.42,\n 48.27,\n 37.8,\n 36.83,\n 9.32,\n 4.73,\n 55.97,\n 20.200000000000003,\n 29.409999999999997,\n 37.04,\n 11.24,\n 6.54,\n 13.889999999999999,\n 36.83,\n 58.45,\n 22.73,\n 37.88,\n 15.15,\n 23.810000000000002,\n 40.73,\n 10.31,\n 32.07,\n 9.43,\n 27.650000000000002,\n 13.889999999999999,\n 60.089999999999996,\n 45.300000000000004,\n 15.82,\n 56.82000000000001,\n 16.85,\n 23.810000000000002,\n 19.07,\n 42.64,\n 9.26,\n 18.02,\n 15.620000000000001,\n 69.44,\n 14.93,\n 18.69,\n 11.81,\n 51.370000000000005,\n 10.870000000000001,\n 14.02,\n 10.100000000000001,\n 43.769999999999996,\n 29.409999999999997,\n 11.63,\n 42.76,\n 31.56,\n 14.45,\n 38.12,\n 52.56999999999999,\n 86.48,\n 38.72,\n 10.639999999999999,\n 10.42,\n 14.08,\n 19.73,\n 23.549999999999997,\n 7.5200000000000005,\n 28.96,\n 39.45,\n 10.530000000000001,\n 6.3100000000000005,\n 84.15,\n 31.790000000000003,\n 37.04,\n 18.990000000000002,\n 13.04,\n 35.260000000000005,\n 12.35,\n 63.71,\n 16.13,\n 18.29,\n 59.43000000000001,\n 10.56,\n 14.29,\n 23.44,\n 24.79,\n 44.45,\n 6.7299999999999995,\n 7.46,\n 8.77,\n 29.520000000000003,\n 21.43,\n 38.49]"
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T11:25:02.470536Z",
     "start_time": "2024-07-31T11:25:02.446710Z"
    }
   },
   "id": "26d6c0e0e29ad11e"
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "my = './standard_json_file.json'\n",
    "my = json.load(open(my, 'r'))[:100]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T12:29:48.137658Z",
     "start_time": "2024-07-18T12:29:48.063529Z"
    }
   },
   "id": "329a4d305b7d7086"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "[{'id': 0,\n  'code': \"def resource_patch(context, data_dict):\\n _check_access('resource_patch', context, data_dict)\\n show_context = {'model': context['model'], 'session': context['session'], 'user': context['user'], 'auth_user_obj': context['auth_user_obj']}\\n resource_dict = _get_action('resource_show')(show_context, {'id': _get_or_bust(data_dict, 'id')})\\n patched = dict(resource_dict)\\n patched.update(data_dict)\\n return _update.resource_update(context, patched)\\n\",\n  'predictions': ['patch a resource .'],\n  'references': ['patch a resource .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 1,\n  'code': \"def pyramid_laplacian(image, max_layer=(-1), downscale=2, sigma=None, order=1, mode='reflect', cval=0):\\n _check_factor(downscale)\\n image = img_as_float(image)\\n if (sigma is None):\\n  sigma = ((2 * downscale) / 6.0)\\n layer = 0\\n rows = image.shape[0]\\n cols = image.shape[1]\\n smoothed_image = _smooth(image, sigma, mode, cval)\\n (yield (image - smoothed_image))\\n while (layer != max_layer):\\n  layer += 1\\n  out_rows = math.ceil((rows / float(downscale)))\\n  out_cols = math.ceil((cols / float(downscale)))\\n  resized_image = resize(smoothed_image, (out_rows, out_cols), order=order, mode=mode, cval=cval)\\n  smoothed_image = _smooth(resized_image, sigma, mode, cval)\\n  prev_rows = rows\\n  prev_cols = cols\\n  rows = resized_image.shape[0]\\n  cols = resized_image.shape[1]\\n  if ((prev_rows == rows) and (prev_cols == cols)):\\n   break\\n  (yield (resized_image - smoothed_image))\\n\",\n  'predictions': ['upsample a single laplacian image .'],\n  'references': ['yield images of the laplacian pyramid formed by the input image .'],\n  'bleu': 0.11492332782473744,\n  'rouge_l': 0.31443298969072164},\n {'id': 2,\n  'code': \"def get_fun(fun):\\n with _get_serv(ret=None, commit=True) as cur:\\n  sql = 'SELECT s.id,s.jid, s.full_ret\\\\n                FROM salt_returns s\\\\n                JOIN ( SELECT MAX(`jid`) as jid\\\\n                    from salt_returns GROUP BY fun, id) max\\\\n                ON s.jid = max.jid\\\\n                WHERE s.fun = %s\\\\n                '\\n  cur.execute(sql, (fun,))\\n  data = cur.fetchall()\\n  ret = {}\\n  if data:\\n   for (minion, _, full_ret) in data:\\n    ret[minion] = full_ret\\n  return ret\\n\",\n  'predictions': ['return a dict of the last function called for all minions .'],\n  'references': ['return a dict of the last function called for all minions .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 3,\n  'code': 'def get_svc_avail_path():\\n return AVAIL_SVR_DIRS\\n',\n  'predictions': ['get the available path .'],\n  'references': ['return list of paths that may contain available services .'],\n  'bleu': 0.11115018927487523,\n  'rouge_l': 0.2515463917525773},\n {'id': 4,\n  'code': \"def store_temp_file(filedata, filename, path=None):\\n filename = get_filename_from_path(filename)\\n filename = filename[:100]\\n options = Config()\\n if path:\\n  target_path = path\\n else:\\n  tmp_path = options.cuckoo.get('tmppath', '/tmp')\\n  target_path = os.path.join(tmp_path, 'cuckoo-tmp')\\n if (not os.path.exists(target_path)):\\n  os.mkdir(target_path)\\n tmp_dir = tempfile.mkdtemp(prefix='upload_', dir=target_path)\\n tmp_file_path = os.path.join(tmp_dir, filename)\\n with open(tmp_file_path, 'wb') as tmp_file:\\n  if hasattr(filedata, 'read'):\\n   chunk = filedata.read(1024)\\n   while chunk:\\n    tmp_file.write(chunk)\\n    chunk = filedata.read(1024)\\n  else:\\n   tmp_file.write(filedata)\\n return tmp_file_path\\n\",\n  'predictions': ['create a temp file on disk .'],\n  'references': ['store a temporary file .'],\n  'bleu': 0.22089591134157885,\n  'rouge_l': 0.5154929577464789},\n {'id': 5,\n  'code': 'def _createTargetDirs():\\n if (not os.path.isdir(paths.POCSUITE_OUTPUT_PATH)):\\n  try:\\n   if (not os.path.isdir(paths.POCSUITE_OUTPUT_PATH)):\\n    os.makedirs(paths.POCSUITE_OUTPUT_PATH, 493)\\n   warnMsg = (\"using \\'%s\\' as the output directory\" % paths.POCSUITE_OUTPUT_PATH)\\n   logger.log(CUSTOM_LOGGING.WARNING, warnMsg)\\n  except (OSError, IOError) as ex:\\n   try:\\n    tempDir = tempfile.mkdtemp(prefix=\\'pocsuiteoutput\\')\\n   except Exception as _:\\n    errMsg = (\"unable to write to the temporary directory (\\'%s\\'). \" % _)\\n    errMsg += \\'Please make sure that your disk is not full and \\'\\n    errMsg += \\'that you have sufficient write permissions to \\'\\n    errMsg += \\'create temporary files and/or directories\\'\\n    raise PocsuiteSystemException(errMsg)\\n   warnMsg = \\'unable to create regular output directory \\'\\n   warnMsg += (\"\\'%s\\' (%s). \" % (paths.POCSUITE_OUTPUT_PATH, getUnicode(ex)))\\n   warnMsg += (\"Using temporary directory \\'%s\\' instead\" % getUnicode(tempDir))\\n   logger.log(CUSTOM_LOGGING.WARNING, warnMsg)\\n   paths.POCUSITE_OUTPUT_PATH = tempDir\\n',\n  'predictions': ['creates regular output directory .'],\n  'references': ['create the output directory .'],\n  'bleu': 0.5081327481546147,\n  'rouge_l': 0.6},\n {'id': 6,\n  'code': \"def unhex(s):\\n bits = 0\\n for c in s:\\n  c = bytes((c,))\\n  if ('0' <= c <= '9'):\\n   i = ord('0')\\n  elif ('a' <= c <= 'f'):\\n   i = (ord('a') - 10)\\n  elif ('A' <= c <= 'F'):\\n   i = (ord('A') - 10)\\n  else:\\n   assert False, ('non-hex digit ' + repr(c))\\n  bits = ((bits * 16) + (ord(c) - i))\\n return bits\\n\",\n  'predictions': ['convert a number to a positive integer .'],\n  'references': ['get the integer value of a hexadecimal number .'],\n  'bleu': 0.17795502018438056,\n  'rouge_l': 0.34923664122137404},\n {'id': 7,\n  'code': \"def _setwindowposition(folder_alias, (x, y)):\\n finder = _getfinder()\\n args = {}\\n attrs = {}\\n aeobj_0 = aetypes.ObjectSpecifier(want=aetypes.Type('cfol'), form='alis', seld=folder_alias, fr=None)\\n aeobj_1 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='prop', seld=aetypes.Type('cwnd'), fr=aeobj_0)\\n aeobj_2 = aetypes.ObjectSpecifier(want=aetypes.Type('prop'), form='prop', seld=aetypes.Type('posn'), fr=aeobj_1)\\n args['----'] = aeobj_2\\n args['data'] = [x, y]\\n (_reply, args, attrs) = finder.send('core', 'setd', args, attrs)\\n if args.has_key('errn'):\\n  raise Error, aetools.decodeerror(args)\\n if args.has_key('----'):\\n  return args['----']\\n\",\n  'predictions': ['set the size of a finder window for folder to .'],\n  'references': ['set the size of a finder window for folder to .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 8,\n  'code': 'def walk(top, topdown=True, followlinks=False):\\n names = os.listdir(top)\\n (dirs, nondirs) = ([], [])\\n for name in names:\\n  if path.isdir(path.join(top, name)):\\n   dirs.append(name)\\n  else:\\n   nondirs.append(name)\\n if topdown:\\n  (yield (top, dirs, nondirs))\\n for name in dirs:\\n  fullpath = path.join(top, name)\\n  if (followlinks or (not path.islink(fullpath))):\\n   for x in walk(fullpath, topdown, followlinks):\\n    (yield x)\\n if (not topdown):\\n  (yield (top, dirs, nondirs))\\n',\n  'predictions': ['backport of os .'],\n  'references': ['backport of os .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 9,\n  'code': \"def url_filename(url):\\n match = upload_title_re.match(url)\\n if match:\\n  return match.group('filename')\\n else:\\n  return url\\n\",\n  'predictions': ['return the filename of a url .'],\n  'references': ['extract the filename if a url is an uploaded file .'],\n  'bleu': 0.18168644632623684,\n  'rouge_l': 0.5341506129597198},\n {'id': 10,\n  'code': \"@testing.requires_testing_data\\n@requires_mne\\ndef test_other_volume_source_spaces():\\n tempdir = _TempDir()\\n temp_name = op.join(tempdir, 'temp-src.fif')\\n run_subprocess(['mne_volume_source_space', '--grid', '7.0', '--src', temp_name, '--mri', fname_mri])\\n src = read_source_spaces(temp_name)\\n src_new = setup_volume_source_space(None, pos=7.0, mri=fname_mri, subjects_dir=subjects_dir)\\n _compare_source_spaces(src, src_new, mode='approx')\\n assert_true(('volume, shape' in repr(src)))\\n del src\\n del src_new\\n assert_raises(ValueError, setup_volume_source_space, 'sample', temp_name, pos=7.0, sphere=[1.0, 1.0], mri=fname_mri, subjects_dir=subjects_dir)\\n run_subprocess(['mne_volume_source_space', '--grid', '7.0', '--src', temp_name])\\n assert_raises(ValueError, read_source_spaces, temp_name)\\n\",\n  'predictions': ['test setting up volume source spaces .'],\n  'references': ['test setting up other volume source spaces .'],\n  'bleu': 0.5993954153807813,\n  'rouge_l': 0.9222462203023757},\n {'id': 11,\n  'code': \"def get_preamble():\\n latex_preamble = rcParams.get(u'pgf.preamble', u'')\\n if (type(latex_preamble) == list):\\n  latex_preamble = u'\\\\n'.join(latex_preamble)\\n return latex_preamble\\n\",\n  'predictions': ['returns the timezone .'],\n  'references': ['get latex preamble from rc .'],\n  'bleu': 0.2179289600664314,\n  'rouge_l': 0.1930379746835443},\n {'id': 12,\n  'code': 'def sdm_spoly(f, g, O, K, phantom=None):\\n if ((not f) or (not g)):\\n  return sdm_zero()\\n LM1 = sdm_LM(f)\\n LM2 = sdm_LM(g)\\n if (LM1[0] != LM2[0]):\\n  return sdm_zero()\\n LM1 = LM1[1:]\\n LM2 = LM2[1:]\\n lcm = monomial_lcm(LM1, LM2)\\n m1 = monomial_div(lcm, LM1)\\n m2 = monomial_div(lcm, LM2)\\n c = K.quo((- sdm_LC(f, K)), sdm_LC(g, K))\\n r1 = sdm_add(sdm_mul_term(f, (m1, K.one), O, K), sdm_mul_term(g, (m2, c), O, K), O, K)\\n if (phantom is None):\\n  return r1\\n r2 = sdm_add(sdm_mul_term(phantom[0], (m1, K.one), O, K), sdm_mul_term(phantom[1], (m2, c), O, K), O, K)\\n return (r1, r2)\\n',\n  'predictions': ['compute subresultant prs of two univariate polynomials in k[x] .'],\n  'references': ['compute the generalized s-polynomial of f and g .'],\n  'bleu': 0.14991106946711685,\n  'rouge_l': 0.31881533101045295},\n {'id': 13,\n  'code': \"def upgrade(migrate_engine):\\n meta = MetaData()\\n meta.bind = migrate_engine\\n volume_type_projects = Table('volume_type_projects', meta, autoload=True)\\n if (migrate_engine.name == 'postgresql'):\\n  sql = ('ALTER TABLE volume_type_projects ALTER COLUMN deleted ' + 'TYPE INTEGER USING deleted::integer')\\n  migrate_engine.execute(sql)\\n else:\\n  volume_type_projects.c.deleted.alter(Integer)\\n\",\n  'predictions': ['upgrade projects for the integer table .'],\n  'references': ['deleted col of volume_type_projects converted .'],\n  'bleu': 0.18575057999133598,\n  'rouge_l': 0.15601023017902813},\n {'id': 14,\n  'code': \"def analyze_modules(project, task_handle=taskhandle.NullTaskHandle()):\\n resources = project.get_python_files()\\n job_set = task_handle.create_jobset('Analyzing Modules', len(resources))\\n for resource in resources:\\n  job_set.started_job(resource.path)\\n  analyze_module(project, resource)\\n  job_set.finished_job()\\n\",\n  'predictions': ['iterate over records and provided resources .'],\n  'references': ['perform static object analysis on all python files in the project note that this might be really time consuming .'],\n  'bleu': 0.0289990174645553,\n  'rouge_l': 0.0681564245810056},\n {'id': 15,\n  'code': \"def get_sw_login_version():\\n return '-'.join(get_sw_version(strip_build_num=True).split('-')[1:(-2)])\\n\",\n  'predictions': ['return the software login version .'],\n  'references': ['return a shortened version string .'],\n  'bleu': 0.2626909894424158,\n  'rouge_l': 0.5},\n {'id': 16,\n  'code': \"def SetHelpMenuOtherHelp(mainMenu):\\n global helpIDMap\\n if (helpIDMap is None):\\n  helpIDMap = {}\\n  cmdID = win32ui.ID_HELP_OTHER\\n  excludeList = ['Main Python Documentation', 'Pythonwin Reference']\\n  firstList = ListAllHelpFiles()\\n  excludeFnames = []\\n  for (desc, fname) in firstList:\\n   if (desc in excludeList):\\n    excludeFnames.append(fname)\\n  helpDescs = []\\n  for (desc, fname) in firstList:\\n   if (fname not in excludeFnames):\\n    helpIDMap[cmdID] = (desc, fname)\\n    win32ui.GetMainFrame().HookCommand(HandleHelpOtherCommand, cmdID)\\n    cmdID = (cmdID + 1)\\n helpMenu = mainMenu.GetSubMenu((mainMenu.GetMenuItemCount() - 1))\\n otherHelpMenuPos = 2\\n otherMenu = helpMenu.GetSubMenu(otherHelpMenuPos)\\n while otherMenu.GetMenuItemCount():\\n  otherMenu.DeleteMenu(0, win32con.MF_BYPOSITION)\\n if helpIDMap:\\n  for (id, (desc, fname)) in helpIDMap.iteritems():\\n   otherMenu.AppendMenu((win32con.MF_ENABLED | win32con.MF_STRING), id, desc)\\n else:\\n  helpMenu.EnableMenuItem(otherHelpMenuPos, (win32con.MF_BYPOSITION | win32con.MF_GRAYED))\\n\",\n  'predictions': ['add the help menu for the main solve .'],\n  'references': ['modifies the main help menu to handle all registered help files .'],\n  'bleu': 0.1751643270174889,\n  'rouge_l': 0.3713850837138508},\n {'id': 17,\n  'code': \"def to(location, code=falcon.HTTP_302):\\n raise falcon.http_status.HTTPStatus(code, {'location': location})\\n\",\n  'predictions': ['send a location to the specified location .'],\n  'references': ['redirects to the specified location using the provided http_code .'],\n  'bleu': 0.3638074228571147,\n  'rouge_l': 0.5446428571428571},\n {'id': 18,\n  'code': \"def select_command(corrected_commands):\\n try:\\n  selector = CommandSelector(corrected_commands)\\n except NoRuleMatched:\\n  logs.failed('No fucks given')\\n  return\\n if (not settings.require_confirmation):\\n  logs.show_corrected_command(selector.value)\\n  return selector.value\\n logs.confirm_text(selector.value)\\n for action in read_actions():\\n  if (action == const.ACTION_SELECT):\\n   sys.stderr.write('\\\\n')\\n   return selector.value\\n  elif (action == const.ACTION_ABORT):\\n   logs.failed('\\\\nAborted')\\n   return\\n  elif (action == const.ACTION_PREVIOUS):\\n   selector.previous()\\n   logs.confirm_text(selector.value)\\n  elif (action == const.ACTION_NEXT):\\n   selector.next()\\n   logs.confirm_text(selector.value)\\n\",\n  'predictions': ['wraps djangos command .'],\n  'references': ['returns: - the first command when confirmation disabled; - none when ctrl+c pressed; - selected command .'],\n  'bleu': 0.018335190851298155,\n  'rouge_l': 0.17134831460674158},\n {'id': 19,\n  'code': 'def partial_project(endog, exog):\\n (x1, x2) = (endog, exog)\\n params = np.linalg.pinv(x2).dot(x1)\\n predicted = x2.dot(params)\\n residual = (x1 - predicted)\\n res = Bunch(params=params, fittedvalues=predicted, resid=residual)\\n return res\\n',\n  'predictions': ['perform initial project parameters endog : ndarray .'],\n  'references': ['helper function to get linear projection or partialling out of variables endog variables are projected on exog variables parameters endog : ndarray array of variables where the effect of exog'],\n  'bleu': 0.028532514035344913,\n  'rouge_l': 0.190625},\n {'id': 20,\n  'code': \"def update(directory, composer=None, php=None, runas=None, prefer_source=None, prefer_dist=None, no_scripts=None, no_plugins=None, optimize=None, no_dev=None, quiet=False, composer_home='/root'):\\n result = _run_composer('update', directory=directory, extra_flags='--no-progress', composer=composer, php=php, runas=runas, prefer_source=prefer_source, prefer_dist=prefer_dist, no_scripts=no_scripts, no_plugins=no_plugins, optimize=optimize, no_dev=no_dev, quiet=quiet, composer_home=composer_home)\\n return result\\n\",\n  'predictions': ['update a ~astropy .'],\n  'references': ['update composer dependencies for a directory .'],\n  'bleu': 0.20183609024241697,\n  'rouge_l': 0.5198863636363635},\n {'id': 21,\n  'code': \"def testOnSequenceData(module, dataset):\\n target = dataset.getField('target')\\n output = ModuleValidator.calculateModuleOutput(module, dataset)\\n ends = SequenceHelper.getSequenceEnds(dataset)\\n summed_output = zeros(dataset.outdim)\\n class_output = []\\n class_target = []\\n for j in range(len(output)):\\n  summed_output += output[j]\\n  if (j in ends):\\n   class_output.append(argmax(summed_output))\\n   class_target.append(argmax(target[j]))\\n   summed_output = zeros(dataset.outdim)\\n class_output = array(class_output)\\n class_target = array(class_target)\\n return Validator.classificationPerformance(class_output, class_target)\\n\",\n  'predictions': ['returns the target class of given sequence data .'],\n  'references': ['fetch targets and calculate the modules output on dataset .'],\n  'bleu': 0.1397712139461423,\n  'rouge_l': 0.20854700854700853},\n {'id': 22,\n  'code': \"@retry_on_failure\\ndef test_inet_pton():\\n if (not is_cli):\\n  return\\n socket.inet_pton(socket.AF_INET, '127.0.0.1')\\n AssertError(socket.error, socket.inet_pton, socket.AF_INET, 'garbage dkfjdkfjdkfj')\\n\",\n  'predictions': ['tests socket .'],\n  'references': ['tests socket .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 23,\n  'code': 'def getPath(edges, pathIndexes, loop, z):\\n path = []\\n for pathIndexIndex in xrange(len(pathIndexes)):\\n  pathIndex = pathIndexes[pathIndexIndex]\\n  edge = edges[pathIndex]\\n  carveIntersection = getCarveIntersectionFromEdge(edge, loop, z)\\n  path.append(carveIntersection)\\n return path\\n',\n  'predictions': ['get the path from the loop .'],\n  'references': ['get the path from the edge intersections .'],\n  'bleu': 0.6129752413741055,\n  'rouge_l': 0.7904967602591793},\n {'id': 24,\n  'code': \"@blueprint.route('/<job_id>.json', methods=['GET'])\\n@blueprint.route('/<job_id>', methods=['GET'])\\ndef show(job_id):\\n job = scheduler.get_job(job_id)\\n if (job is None):\\n  raise werkzeug.exceptions.NotFound('Job not found')\\n related_jobs = scheduler.get_related_jobs(job)\\n if request_wants_json():\\n  return flask.jsonify(job.json_dict(True))\\n elif isinstance(job, model_images.ImageClassificationModelJob):\\n  return model_images.classification.views.show(job, related_jobs=related_jobs)\\n elif isinstance(job, model_images.GenericImageModelJob):\\n  return model_images.generic.views.show(job, related_jobs=related_jobs)\\n else:\\n  raise werkzeug.exceptions.BadRequest('Invalid job type')\\n\",\n  'predictions': ['show a datasetjob returns json when requested: {id .'],\n  'references': ['show a modeljob returns json when requested: {id .'],\n  'bleu': 0.7071067811865475,\n  'rouge_l': 0.8888888888888888},\n {'id': 25,\n  'code': 'def test(condition, true, false):\\n if condition:\\n  return true\\n else:\\n  return false\\n',\n  'predictions': ['returns true if the condition is accelerate .'],\n  'references': ['implements the c expression: condition ? true : false required to correctly interpret plural forms .'],\n  'bleu': 0.0741826891259906,\n  'rouge_l': 0.23582474226804123},\n {'id': 26,\n  'code': 'def _has_required_botocore():\\n if (not HAS_BOTO):\\n  return False\\n elif (LooseVersion(botocore.__version__) < LooseVersion(required_botocore_version)):\\n  return False\\n else:\\n  return True\\n',\n  'predictions': ['returns true/false boolean depending on if boto is installed and correct version .'],\n  'references': ['returns true/false boolean depending on if botocore supports usage plan .'],\n  'bleu': 0.44710186192584195,\n  'rouge_l': 0.5922330097087377},\n {'id': 27,\n  'code': \"def get_load(jid):\\n serv = _get_serv(ret=None)\\n data = serv.get('load:{0}'.format(jid))\\n if data:\\n  return json.loads(data)\\n return {}\\n\",\n  'predictions': ['return the load data that marks a specified jid .'],\n  'references': ['return the load data that marks a specified jid .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 28,\n  'code': \"def config_option_show(context, data_dict):\\n return {'success': False}\\n\",\n  'predictions': ['show the runtime-editable configuration options .'],\n  'references': ['show runtime-editable configuration option .'],\n  'bleu': 0.3303164318013807,\n  'rouge_l': 0.7393939393939394},\n {'id': 29,\n  'code': 'def _default_selem(func):\\n @functools.wraps(func)\\n def func_out(image, selem=None, *args, **kwargs):\\n  if (selem is None):\\n   selem = ndi.generate_binary_structure(image.ndim, image.ndim)\\n  return func(image, selem=selem, *args, **kwargs)\\n return func_out\\n',\n  'predictions': ['decorator to add a default structuring element to morphology functions .'],\n  'references': ['decorator to add a default structuring element to morphology functions .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 30,\n  'code': \"@preserve_value(sys, 'dont_write_bytecode')\\ndef _load_module_no_bytecode(filename, module_file, module_file_path, py_source_description):\\n sys.dont_write_bytecode = 1\\n new_module = imp.load_module(os.path.splitext(filename)[0].replace('-', '_'), module_file, module_file_path, py_source_description)\\n return new_module\\n\",\n  'predictions': ['helper function to load a module while setting sys .'],\n  'references': ['helper function to load a module while setting sys .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 31,\n  'code': \"def populate_tables(db, prefix, tmp_prefix, bounds):\\n bbox = ('ST_SetSRID(ST_MakeBox2D(ST_MakePoint(%.6f, %.6f), ST_MakePoint(%.6f, %.6f)), 900913)' % bounds)\\n db.execute('BEGIN')\\n for table in ('point', 'line', 'roads', 'polygon'):\\n  db.execute(('DELETE FROM %(prefix)s_%(table)s WHERE ST_Intersects(way, %(bbox)s)' % locals()))\\n  db.execute(('INSERT INTO %(prefix)s_%(table)s\\\\n                      SELECT * FROM %(tmp_prefix)s_%(table)s\\\\n                      WHERE ST_Intersects(way, %(bbox)s)' % locals()))\\n db.execute('COMMIT')\\n\",\n  'predictions': ['populate tables .'],\n  'references': ['move prepared osm data from temporary to permanent tables .'],\n  'bleu': 0.06856953606192477,\n  'rouge_l': 0.28045977011494255},\n {'id': 32,\n  'code': 'def is_1pexp(t, only_process_constants=True):\\n if (t.owner and (t.owner.op == tensor.add)):\\n  (scalars, scalar_inputs, nonconsts) = opt.scalarconsts_rest(t.owner.inputs, only_process_constants=only_process_constants)\\n  if (len(nonconsts) == 1):\\n   maybe_exp = nonconsts[0]\\n   if (maybe_exp.owner and (maybe_exp.owner.op == tensor.exp)):\\n    if scalars:\\n     scal_sum = scalars[0]\\n     for s in scalars[1:]:\\n      scal_sum = (scal_sum + s)\\n     if numpy.allclose(scal_sum, 1):\\n      return (False, maybe_exp.owner.inputs[0])\\n    if config.warn.identify_1pexp_bug:\\n     warnings.warn(\"Although your current code is fine, please note that Theano versions prior to 0.5 (more specifically, prior to commit 7987b51 on 2011-12-18) may have yielded an incorrect result. To remove this warning, either set the `warn.identify_1pexp_bug` config option to False, or `warn.ignore_bug_before` to at least \\'0.4.1\\'.\")\\n return None\\n',\n  'predictions': ['this function determines the set of theano .'],\n  'references': ['returns object if t is of the form (1+exp(x)) .'],\n  'bleu': 0.1485237584394808,\n  'rouge_l': 0.21785714285714283},\n {'id': 33,\n  'code': 'def round_if_near_integer(a, epsilon=0.0001):\\n if (abs((a - round(a))) <= epsilon):\\n  return round(a)\\n else:\\n  return a\\n',\n  'predictions': ['round a is near .'],\n  'references': ['round a to the nearest integer if that integer is within an epsilon of a .'],\n  'bleu': 0.045235199979419494,\n  'rouge_l': 0.34807417974322397},\n {'id': 34,\n  'code': \"def make_msgid(idstring=None):\\n timeval = time.time()\\n utcdate = time.strftime(u'%Y%m%d%H%M%S', time.gmtime(timeval))\\n try:\\n  pid = os.getpid()\\n except AttributeError:\\n  pid = 1\\n randint = random.randrange(100000)\\n if (idstring is None):\\n  idstring = u''\\n else:\\n  idstring = (u'.' + idstring)\\n idhost = DNS_NAME\\n msgid = (u'<%s.%s.%s%s@%s>' % (utcdate, pid, randint, idstring, idhost))\\n return msgid\\n\",\n  'predictions': ['returns a string suitable for rfc 2822 compliant message-id .'],\n  'references': ['returns a string suitable for rfc 2822 compliant message-id .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 35,\n  'code': \"def get_linode_id_from_name(name):\\n nodes = _query('linode', 'list')['DATA']\\n linode_id = ''\\n for node in nodes:\\n  if (name == node['LABEL']):\\n   linode_id = node['LINODEID']\\n   return linode_id\\n if (not linode_id):\\n  raise SaltCloudNotFound('The specified name, {0}, could not be found.'.format(name))\\n\",\n  'predictions': ['returns the linode id for a linode .'],\n  'references': ['returns the linode id for a vm from the provided name .'],\n  'bleu': 0.45527638121123265,\n  'rouge_l': 0.6756329113924051},\n {'id': 36,\n  'code': \"def did_you_mean_units(s, all_units, deprecated_units, format_decomposed):\\n def fix_deprecated(x):\\n  if (x in deprecated_units):\\n   results = [(x + u' (deprecated)')]\\n   decomposed = _try_decomposed(all_units[x], format_decomposed)\\n   if (decomposed is not None):\\n    results.append(decomposed)\\n   return results\\n  return (x,)\\n return did_you_mean(s, all_units, fix=fix_deprecated)\\n\",\n  'predictions': ['replaces deprecated units with a deprecated mean .'],\n  'references': ['a wrapper around astropy .'],\n  'bleu': 0.17747405280050269,\n  'rouge_l': 0.32105263157894737},\n {'id': 37,\n  'code': 'def write_block_summary_report(course_data):\\n (block_summary_counts, unique_course_counts) = _get_block_summary_totals(course_data)\\n with open(\\'xblock_summary_counts.csv\\', \\'wb\\') as csvfile:\\n  summary_writer = csv.writer(csvfile, delimiter=\\',\\', quotechar=\\'\"\\', quoting=csv.QUOTE_MINIMAL)\\n  summary_writer.writerow([\\'XBLOCK_NAME\\', \\'UNIQUE_COURSES\\', \\'NUM_TOTAL_INSTANCES\\'])\\n  for block_type in sorted(block_summary_counts):\\n   block_count = block_summary_counts.get(block_type)\\n   summary_writer.writerow([block_type, str(unique_course_counts[block_type]), str(block_count)])\\n  csvfile.close()\\n',\n  'predictions': ['generate a csv summary of the cookiecutter report for the specified course .'],\n  'references': ['generate a csv file containing a summary of the xblock usage arguments: course_data : a list of course_data objects returns: nothing .'],\n  'bleu': 0.13303581397150216,\n  'rouge_l': 0.38227394807520143},\n {'id': 38,\n  'code': \"def test_semisuper_succeeds():\\n with helpers.tempdir() as temp:\\n  env = gym.make('SemisuperPendulumDecay-v0')\\n  env = Monitor(env, temp)\\n  env.reset()\\n  env.step(env.action_space.sample())\\n  env.close()\\n\",\n  'predictions': ['wale_log_destination should load succeeds .'],\n  'references': ['regression test .'],\n  'bleu': 0.2730120862709067,\n  'rouge_l': 0.26180257510729615},\n {'id': 39,\n  'code': \"def is_classifier(estimator):\\n return (getattr(estimator, '_estimator_type', None) == 'classifier')\\n\",\n  'predictions': ['returns true if the given estimator is a classifier .'],\n  'references': ['returns true if the given estimator is a classifier .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 40,\n  'code': \"def istextfile(fp_, blocksize=512):\\n int2byte = ((lambda x: bytes((x,))) if six.PY3 else chr)\\n text_characters = (''.join((int2byte(i) for i in range(32, 127))) + '\\\\n\\\\r DCTB \\\\x0c\\\\x08')\\n try:\\n  block = fp_.read(blocksize)\\n except AttributeError:\\n  try:\\n   with fopen(fp_, 'rb') as fp2_:\\n    block = fp2_.read(blocksize)\\n  except IOError:\\n   return False\\n if ('\\\\x00' in block):\\n  return False\\n elif (not block):\\n  return True\\n try:\\n  block.decode('utf-8')\\n  return True\\n except UnicodeDecodeError:\\n  pass\\n nontext = block.translate(None, text_characters)\\n return ((float(len(nontext)) / len(block)) <= 0.3)\\n\",\n  'predictions': ['attempt to fix the bytes of a block of bytes .'],\n  'references': ['uses heuristics to guess whether the given file is text or binary .'],\n  'bleu': 0.11294012253658708,\n  'rouge_l': 0.24629878869448185},\n {'id': 41,\n  'code': '@register.simple_tag\\ndef bootstrap_css_url():\\n return css_url()\\n',\n  'predictions': ['returns the full url to the bootstrap css file .'],\n  'references': ['return the full url to the bootstrap css library default value: none this value is configurable .'],\n  'bleu': 0.34707874491522756,\n  'rouge_l': 0.5661252900232019},\n {'id': 42,\n  'code': 'def _get_objects(obj_type):\\n lst_objs = FakeRetrieveResult()\\n for key in _db_content[obj_type]:\\n  lst_objs.add_object(_db_content[obj_type][key])\\n return lst_objs\\n',\n  'predictions': ['create method object from the db .'],\n  'references': ['get objects of the type .'],\n  'bleu': 0.20556680845025982,\n  'rouge_l': 0.31202046035805625},\n {'id': 43,\n  'code': \"def expandvars(path):\\n global _varprog\\n if ('$' not in path):\\n  return path\\n if (not _varprog):\\n  import re\\n  _varprog = re.compile('\\\\\\\\$(\\\\\\\\w+|\\\\\\\\{[^}]*\\\\\\\\})')\\n i = 0\\n while True:\\n  m = _varprog.search(path, i)\\n  if (not m):\\n   break\\n  (i, j) = m.span(0)\\n  name = m.group(1)\\n  if (name.startswith('{') and name.endswith('}')):\\n   name = name[1:(-1)]\\n  if (name in os.environ):\\n   tail = path[j:]\\n   path = (path[:i] + os.environ[name])\\n   i = len(path)\\n   path += tail\\n  else:\\n   i = j\\n return path\\n\",\n  'predictions': ['return the directory exists .'],\n  'references': ['expand shell variables of form $var and ${var} .'],\n  'bleu': 0.12267223791558805,\n  'rouge_l': 0.1358574610244989},\n {'id': 44,\n  'code': 'def getNewRepository():\\n return DrillRepository()\\n',\n  'predictions': ['get the repository constructor .'],\n  'references': ['get new repository .'],\n  'bleu': 0.32466791547509893,\n  'rouge_l': 0.6802973977695167},\n {'id': 45,\n  'code': 'def _get_block_types_from_json_file(xblock_json_file):\\n if (not os.path.isfile(xblock_json_file)):\\n  print (\\'xBlock configuration file does not exist: %s\\' % xblock_json_file)\\n  sys.exit(2)\\n with open(xblock_json_file, \\'r\\') as json_file:\\n  type_set = set()\\n  try:\\n   json_data = json.loads(json_file.read())\\n  except ValueError as e:\\n   print (\\'xBlock configuration file does not match the expected layout and is missing \"data\" list: %s\\' % xblock_json_file)\\n   sys.exit(e.message)\\n  if (\\'data\\' in json_data):\\n   xblock_type_list = json_data[\\'data\\']\\n   for xblock in xblock_type_list:\\n    type_set.add(xblock[\\'name\\'])\\n   return type_set\\n  else:\\n   print (\\'xBlock configuration file does not match the expected layout and is missing \"data\" list: %s\\' % xblock_json_file)\\n   sys.exit(2)\\n',\n  'predictions': ['retrieve a list of information from the specified xblock file .'],\n  'references': ['retrieves the block types from the provided xblock configuration json file arguments: xblock_json_file : the name of the xblock configuration file :return: set: a set of strings for all the'],\n  'bleu': 0.03293691238648973,\n  'rouge_l': 0.18007380073800738},\n {'id': 46,\n  'code': 'def ValidateActionsInTarget(target, target_dict, build_file):\\n target_name = target_dict.get(\\'target_name\\')\\n actions = target_dict.get(\\'actions\\', [])\\n for action in actions:\\n  action_name = action.get(\\'action_name\\')\\n  if (not action_name):\\n   raise GypError((\"Anonymous action in target %s.  An action must have an \\'action_name\\' field.\" % target_name))\\n  inputs = action.get(\\'inputs\\', None)\\n  if (inputs is None):\\n   raise GypError((\\'Action in target %s has no inputs.\\' % target_name))\\n  action_command = action.get(\\'action\\')\\n  if (action_command and (not action_command[0])):\\n   raise GypError((\\'Empty action as command in target %s.\\' % target_name))\\n',\n  'predictions': ['validate the actions of the given target .'],\n  'references': ['validates the inputs to the actions in a target .'],\n  'bleu': 0.21632118787624222,\n  'rouge_l': 0.43571428571428567},\n {'id': 47,\n  'code': 'def match_hostname(cert, hostname):\\n if (not cert):\\n  raise ValueError(u\\'empty or no certificate\\')\\n dnsnames = []\\n san = cert.get(u\\'subjectAltName\\', ())\\n for (key, value) in san:\\n  if (key == u\\'DNS\\'):\\n   if _dnsname_match(value, hostname):\\n    return\\n   dnsnames.append(value)\\n if (not dnsnames):\\n  for sub in cert.get(u\\'subject\\', ()):\\n   for (key, value) in sub:\\n    if (key == u\\'commonName\\'):\\n     if _dnsname_match(value, hostname):\\n      return\\n     dnsnames.append(value)\\n if (len(dnsnames) > 1):\\n  raise CertificateError((u\"hostname %r doesn\\'t match either of %s\" % (hostname, u\\', \\'.join(map(repr, dnsnames)))))\\n elif (len(dnsnames) == 1):\\n  if ((sys.version_info[:3] < (2, 7, 3)) and (dnsnames[0] == u\\'calibre-ebook.com\\')):\\n   return\\n  raise CertificateError((u\"hostname %r doesn\\'t match %r\" % (hostname, dnsnames[0])))\\n else:\\n  raise CertificateError(u\\'no appropriate commonName or subjectAltName fields were found\\')\\n',\n  'predictions': ['verify that *cert (in decoded format as returned by sslsocket .'],\n  'references': ['verify that *cert (in decoded format as returned by sslsocket .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 48,\n  'code': 'def gf_quo_ground(f, a, p, K):\\n return gf_mul_ground(f, K.invert(a, p), p, K)\\n',\n  'predictions': ['compute f - g*h where f in gf(p)[x] and a in gf(p) .'],\n  'references': ['compute f/a where f in gf(p)[x] and a in gf(p) .'],\n  'bleu': 0.6930977286178778,\n  'rouge_l': 0.8460471567267683},\n {'id': 49,\n  'code': \"def _do_search(conf):\\n connargs = {}\\n for name in ['server', 'port', 'tls', 'binddn', 'bindpw', 'anonymous']:\\n  connargs[name] = _config(name, conf)\\n if (connargs['binddn'] and connargs['bindpw']):\\n  connargs['anonymous'] = False\\n try:\\n  _filter = conf['filter']\\n except KeyError:\\n  raise SaltInvocationError('missing filter')\\n _dn = _config('dn', conf)\\n scope = _config('scope', conf)\\n _lists = (_config('lists', conf) or [])\\n _attrs = (_config('attrs', conf) or [])\\n attrs = (_lists + _attrs)\\n if (not attrs):\\n  attrs = None\\n try:\\n  result = __salt__['ldap.search'](_filter, _dn, scope, attrs, **connargs)['results']\\n except IndexError:\\n  log.debug('LDAP search returned no results for filter {0}'.format(_filter))\\n  result = {}\\n except Exception:\\n  log.critical('Failed to retrieve pillar data from LDAP:\\\\n', exc_info=True)\\n  return {}\\n return result\\n\",\n  'predictions': ['search a given a list from pillar .'],\n  'references': ['builds connection and search arguments .'],\n  'bleu': 0.17747405280050269,\n  'rouge_l': 0.2932692307692307},\n {'id': 50,\n  'code': 'def test_rus_fit():\\n rus = RandomUnderSampler(random_state=RND_SEED)\\n rus.fit(X, Y)\\n assert_equal(rus.min_c_, 0)\\n assert_equal(rus.maj_c_, 1)\\n assert_equal(rus.stats_c_[0], 3)\\n assert_equal(rus.stats_c_[1], 7)\\n',\n  'predictions': ['test the fitting method .'],\n  'references': ['test the fitting method .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 51,\n  'code': 'def MissingMetricsCriteria():\\n return ([], [])\\n',\n  'predictions': ['return the rest api that was used for our metrics .'],\n  'references': ['this criteria is alerted if metrics data is completely missing at a timestamp .'],\n  'bleu': 0.09596928383261212,\n  'rouge_l': 0.15661103979460847},\n {'id': 52,\n  'code': \"def FlagOverrider(**flag_kwargs):\\n def Decorator(f):\\n  'Allow a function to safely change flags, restoring them on return.'\\n  def Decorated(*args, **kwargs):\\n   global FLAGS\\n   old_flags = copy.copy(FLAGS)\\n   for (k, v) in flag_kwargs.items():\\n    setattr(FLAGS, k, v)\\n   try:\\n    return f(*args, **kwargs)\\n   finally:\\n    FLAGS = old_flags\\n  return Decorated\\n return Decorator\\n\",\n  'predictions': ['decorator: overrider .'],\n  'references': ['a helpful decorator which can switch the flag values temporarily .'],\n  'bleu': 0.03733241372167512,\n  'rouge_l': 0.1295116772823779},\n {'id': 53,\n  'code': 'def follow_link(connection, link):\\n if link:\\n  return connection.follow_link(link)\\n else:\\n  return None\\n',\n  'predictions': ['this method returns the link which could sets of link .'],\n  'references': ['this method returns the entity of the element which link points to .'],\n  'bleu': 0.30615876303600453,\n  'rouge_l': 0.5746971736204576},\n {'id': 54,\n  'code': \"def add_arg(f, *args, **kwargs):\\n if (not hasattr(f, 'arguments')):\\n  f.arguments = []\\n if ((args, kwargs) not in f.arguments):\\n  f.arguments.insert(0, (args, kwargs))\\n\",\n  'predictions': ['adds an http function to the command .'],\n  'references': ['bind cli arguments to a shell .'],\n  'bleu': 0.17747405280050269,\n  'rouge_l': 0.26991150442477874},\n {'id': 55,\n  'code': 'def singleton(cls):\\n _instances = {}\\n def get_instance(*args, **kwargs):\\n  if (cls not in _instances):\\n   _instances[cls] = cls(*args, **kwargs)\\n  return _instances[cls]\\n return get_instance\\n',\n  'predictions': ['simple wrapper to create a class .'],\n  'references': ['from pep-318 url#examples .'],\n  'bleu': 0.18575057999133598,\n  'rouge_l': 0.19122257053291536},\n {'id': 56,\n  'code': 'def _get_pseudo_pgp_block(remaining_contents):\\n if (not remaining_contents):\\n  return None\\n block_match = PGP_BLOCK_START.match(remaining_contents[0])\\n if block_match:\\n  block_type = block_match.groups()[0]\\n  block_lines = []\\n  end_line = (PGP_BLOCK_END % block_type)\\n  while True:\\n   if (not remaining_contents):\\n    raise ValueError((\"Unterminated pgp style block (looking for \\'%s\\'):\\\\n%s\" % (end_line, \\'\\\\n\\'.join(block_lines))))\\n   line = remaining_contents.pop(0)\\n   block_lines.append(line)\\n   if (line == end_line):\\n    return (block_type, \\'\\\\n\\'.join(block_lines))\\n else:\\n  return None\\n',\n  'predictions': ['return pseudo pgp block for the latest block .'],\n  'references': ['checks if given contents begins with a pseudo-open-pgp-style block and .'],\n  'bleu': 0.12507277759788113,\n  'rouge_l': 0.19645732689210954},\n {'id': 57,\n  'code': \"def plugin_cache_dir():\\n return os.path.join(tempfile.gettempdir(), 'UltiSnips_test_vim_plugins')\\n\",\n  'predictions': ['return the configuration cache directory .'],\n  'references': ['the directory that we check out our bundles to .'],\n  'bleu': 0.13487005099534619,\n  'rouge_l': 0.3588235294117647},\n {'id': 58,\n  'code': 'def keywords(text):\\n NUM_KEYWORDS = 10\\n text = split_words(text)\\n if text:\\n  num_words = len(text)\\n  text = [x for x in text if (x not in stopwords)]\\n  freq = {}\\n  for word in text:\\n   if (word in freq):\\n    freq[word] += 1\\n   else:\\n    freq[word] = 1\\n  min_size = min(NUM_KEYWORDS, len(freq))\\n  keywords = sorted(freq.items(), key=(lambda x: (x[1], x[0])), reverse=True)\\n  keywords = keywords[:min_size]\\n  keywords = dict(((x, y) for (x, y) in keywords))\\n  for k in keywords:\\n   articleScore = ((keywords[k] * 1.0) / max(num_words, 1))\\n   keywords[k] = ((articleScore * 1.5) + 1)\\n  return dict(keywords)\\n else:\\n  return dict()\\n',\n  'predictions': ['given a host .'],\n  'references': ['get the top 10 keywords and their frequency scores ignores blacklisted words in stopwords .'],\n  'bleu': 0.022969543400575367,\n  'rouge_l': 0.0953125},\n {'id': 59,\n  'code': \"def escape(s):\\n if (s is None):\\n  return ''\\n assert isinstance(s, basestring), ('expected %s but got %s; value=%s' % (basestring, type(s), s))\\n s = s.replace('\\\\\\\\', '\\\\\\\\\\\\\\\\')\\n s = s.replace('\\\\n', '\\\\\\\\n')\\n s = s.replace(' DCTB ', '\\\\\\\\t')\\n s = s.replace(',', ' DCTB ')\\n return s\\n\",\n  'predictions': ['escape commas .'],\n  'references': ['escape commas .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 60,\n  'code': \"def after_script():\\n destroy_cmd = ['terraform', 'destroy', '-force']\\n logging.info('Destroying cloud provider resources')\\n sys.exit(run_cmd(destroy_cmd))\\n\",\n  'predictions': ['clean up after the specified script .'],\n  'references': ['cleanup after ci_build .'],\n  'bleu': 0.20556680845025982,\n  'rouge_l': 0.3824451410658307},\n {'id': 61,\n  'code': 'def standard_b64encode(s):\\n return b64encode(s)\\n',\n  'predictions': ['b64e(s) -> str base64 encodes a string example: .'],\n  'references': ['encode a string using the standard base64 alphabet .'],\n  'bleu': 0.21105340631872635,\n  'rouge_l': 0.3333333333333333},\n {'id': 62,\n  'code': 'def import_buffer_to_ast(buf, module_name):\\n return hy_compile(import_buffer_to_hst(buf), module_name)\\n',\n  'predictions': ['import content from a buf .'],\n  'references': ['import content from buf and return a python ast .'],\n  'bleu': 0.2427799661218293,\n  'rouge_l': 0.5980392156862745},\n {'id': 63,\n  'code': 'def merge_with(func, *dicts, **kwargs):\\n if ((len(dicts) == 1) and (not isinstance(dicts[0], dict))):\\n  dicts = dicts[0]\\n factory = _get_factory(merge_with, kwargs)\\n result = factory()\\n for d in dicts:\\n  for (k, v) in iteritems(d):\\n   if (k not in result):\\n    result[k] = [v]\\n   else:\\n    result[k].append(v)\\n return valmap(func, result, factory)\\n',\n  'predictions': ['merge multiple dictionaries with one or more dicts .'],\n  'references': ['merge dictionaries and apply function to combined values a key may occur in more than one dict .'],\n  'bleu': 0.06833381956448396,\n  'rouge_l': 0.27949599083619703},\n {'id': 64,\n  'code': 'def textListToColorsSimple(names):\\n uNames = list(set(names))\\n uNames.sort()\\n textToColor = [uNames.index(n) for n in names]\\n textToColor = np.array(textToColor)\\n textToColor = ((255 * (textToColor - textToColor.min())) / (textToColor.max() - textToColor.min()))\\n textmaps = generateColorMap()\\n colors = [textmaps[int(c)] for c in textToColor]\\n return colors\\n',\n  'predictions': ['generates a list of colors based on a list of names .'],\n  'references': ['generates a list of colors based on a list of names .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 65,\n  'code': 'def multidict_to_dict(multidict):\\n if config.AUTO_COLLAPSE_MULTI_KEYS:\\n  d = dict(multidict.lists())\\n  for (key, value) in d.items():\\n   if (len(value) == 1):\\n    d[key] = value[0]\\n  return d\\n else:\\n  return multidict.to_dict()\\n',\n  'predictions': ['converts a dictionary to a list of dicts .'],\n  'references': ['convert a multidict containing form data into a regular dict .'],\n  'bleu': 0.1343994460963362,\n  'rouge_l': 0.2946859903381642},\n {'id': 66,\n  'code': \"def get_can_enable_ldap():\\n if has_module(u'ldap'):\\n  return (True, None)\\n else:\\n  return (False, _(u'LDAP authentication requires the python-ldap library, which is not installed.'))\\n\",\n  'predictions': ['check whether the specified kernel library is installed .'],\n  'references': ['check whether ldap authentication can be enabled .'],\n  'bleu': 0.19960198807747329,\n  'rouge_l': 0.35672514619883033},\n {'id': 67,\n  'code': 'def escape_all(v, linkify=True):\\n if isinstance(v, basestring):\\n  v = jinja2.escape(smart_unicode(v))\\n  if linkify:\\n   v = bleach.linkify(v, callbacks=[bleach.callbacks.nofollow])\\n  return v\\n elif isinstance(v, list):\\n  for (i, lv) in enumerate(v):\\n   v[i] = escape_all(lv, linkify=linkify)\\n elif isinstance(v, dict):\\n  for (k, lv) in v.iteritems():\\n   v[k] = escape_all(lv, linkify=linkify)\\n elif isinstance(v, Translation):\\n  v = jinja2.escape(smart_unicode(v.localized_string))\\n return v\\n',\n  'predictions': ['escape html in json value .'],\n  'references': ['escape html in json value .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 68,\n  'code': 'def strip_html(unclean):\\n if ((not isinstance(unclean, basestring)) and (not is_iterable(unclean)) and (unclean is not None)):\\n  return unclean\\n return bleach.clean(unclean, strip=True, tags=[], attributes=[], styles=[])\\n',\n  'predictions': ['strips html markup from an html string .'],\n  'references': ['sanitize a string .'],\n  'bleu': 0.21105340631872638,\n  'rouge_l': 0.3546511627906977},\n {'id': 69,\n  'code': 'def get_ident():\\n return (-1)\\n',\n  'predictions': ['return the value returns a string .'],\n  'references': ['dummy implementation of thread .'],\n  'bleu': 0.18575057999133598,\n  'rouge_l': 0.17183098591549298},\n {'id': 70,\n  'code': 'def get_health(**kwargs):\\n with _IpmiCommand(**kwargs) as s:\\n  return s.get_health()\\n',\n  'predictions': ['return the name of the health health .'],\n  'references': ['get summarize health this provides a summary of the health of the managed system .'],\n  'bleu': 0.143106448612759,\n  'rouge_l': 0.32972972972972975},\n {'id': 71,\n  'code': \"def isunauthenticated(f):\\n return getattr(f, 'unauthenticated', False)\\n\",\n  'predictions': ['decorator to see if the function is a repository .'],\n  'references': ['checks to see if the function is marked as not requiring authentication with the @unauthenticated decorator .'],\n  'bleu': 0.30176474924624197,\n  'rouge_l': 0.4953596287703016},\n {'id': 72,\n  'code': 'def agent_leave(consul_url=None, node=None):\\n ret = {}\\n query_params = {}\\n if (not consul_url):\\n  consul_url = _get_config()\\n  if (not consul_url):\\n   log.error(\\'No Consul URL found.\\')\\n   ret[\\'message\\'] = \\'No Consul URL found.\\'\\n   ret[\\'res\\'] = False\\n   return ret\\n if (not node):\\n  raise SaltInvocationError(\\'Required argument \"node\" is missing.\\')\\n function = \\'agent/force-leave/{0}\\'.format(node)\\n res = _query(consul_url=consul_url, function=function, method=\\'GET\\', query_params=query_params)\\n if res[\\'res\\']:\\n  ret[\\'res\\'] = True\\n  ret[\\'message\\'] = \\'Node {0} put in leave state.\\'.format(node)\\n else:\\n  ret[\\'res\\'] = False\\n  ret[\\'message\\'] = \\'Unable to change state for {0}.\\'.format(node)\\n return ret\\n',\n  'predictions': ['information about the agent .'],\n  'references': ['used to instruct the agent to force a node into the left state .'],\n  'bleu': 0.06382147015463427,\n  'rouge_l': 0.2909379968203497},\n {'id': 73,\n  'code': \"def make_dist(name, version, **kwargs):\\n summary = kwargs.pop(u'summary', u'Placeholder for summary')\\n md = Metadata(**kwargs)\\n md.name = name\\n md.version = version\\n md.summary = (summary or u'Plaeholder for summary')\\n return Distribution(md)\\n\",\n  'predictions': ['a convenience method for making a dist given just a name and version .'],\n  'references': ['a convenience method for making a dist given just a name and version .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 74,\n  'code': \"def task_cli_pip_prereqs(package_manager):\\n if (package_manager in ('dnf', 'yum')):\\n  return yum_install(PIP_CLI_PREREQ_YUM, package_manager=package_manager, sudo=True)\\n elif (package_manager == 'apt'):\\n  return sequence([apt_get_update(sudo=True), apt_get_install(PIP_CLI_PREREQ_APT, sudo=True)])\\n else:\\n  raise UnsupportedDistribution()\\n\",\n  'predictions': ['install or not the package specified in managed packages .'],\n  'references': ['install the pre-requisites for pip installation of the flocker client .'],\n  'bleu': 0.13564514503163538,\n  'rouge_l': 0.28328173374613},\n {'id': 75,\n  'code': \"@public\\ndef pdiv(f, g, *gens, **args):\\n options.allowed_flags(args, ['polys'])\\n try:\\n  ((F, G), opt) = parallel_poly_from_expr((f, g), *gens, **args)\\n except PolificationFailed as exc:\\n  raise ComputationFailed('pdiv', 2, exc)\\n (q, r) = F.pdiv(G)\\n if (not opt.polys):\\n  return (q.as_expr(), r.as_expr())\\n else:\\n  return (q, r)\\n\",\n  'predictions': ['compute polynomial pseudo-remainder of f and g .'],\n  'references': ['compute polynomial pseudo-division of f and g .'],\n  'bleu': 0.6606328636027614,\n  'rouge_l': 0.875},\n {'id': 76,\n  'code': \"def count_values(expr, sort=True):\\n result = by(expr, count=expr.count())\\n if sort:\\n  result = result.sort('count', ascending=False)\\n return result\\n\",\n  'predictions': ['counts the number of values in a matcher .'],\n  'references': ['count occurrences of elements in this column sort by counts by default add sort=false keyword to avoid this behavior .'],\n  'bleu': 0.05227938863320699,\n  'rouge_l': 0.19365079365079363},\n {'id': 77,\n  'code': 'def pairwise_most_common(sets):\\n from sympy.utilities.iterables import subsets\\n from collections import defaultdict\\n most = (-1)\\n for (i, j) in subsets(list(range(len(sets))), 2):\\n  com = (sets[i] & sets[j])\\n  if (com and (len(com) > most)):\\n   best = defaultdict(list)\\n   best_keys = []\\n   most = len(com)\\n  if (len(com) == most):\\n   if (com not in best_keys):\\n    best_keys.append(com)\\n   best[best_keys.index(com)].append((i, j))\\n if (most == (-1)):\\n  return []\\n for k in range(len(best)):\\n  best_keys[k] = (best_keys[k], best[k])\\n best_keys.sort(key=(lambda x: len(x[1])))\\n return best_keys\\n',\n  'predictions': ['find the list of best indices for a list of best .'],\n  'references': ['return a list of tuples where s is the largest subset of elements that appear in pairs of sets given by sets and l is a list of tuples giving'],\n  'bleu': 0.05333053777138808,\n  'rouge_l': 0.22101449275362317},\n {'id': 78,\n  'code': 'def yaml_dump(object):\\n yaml = get_yaml()\\n return yaml.dump(object, Dumper=yaml.RoundTripDumper, block_seq_indent=2, default_flow_style=False, indent=2)\\n',\n  'predictions': ['special yaml .'],\n  'references': ['dump object to string .'],\n  'bleu': 0.2758512992979459,\n  'rouge_l': 0.23921568627450981},\n {'id': 79,\n  'code': 'def serve_file(load, fnd):\\n if (\\'env\\' in load):\\n  salt.utils.warn_until(\\'Oxygen\\', \"Parameter \\'env\\' has been detected in the argument list.  This parameter is no longer used and has been replaced by \\'saltenv\\' as of Salt 2016.11.0.  This warning will be removed in Salt Oxygen.\")\\n  load.pop(\\'env\\')\\n ret = {\\'data\\': \\'\\', \\'dest\\': \\'\\'}\\n if ((\\'path\\' not in load) or (\\'loc\\' not in load) or (\\'saltenv\\' not in load)):\\n  return ret\\n if (not fnd[\\'path\\']):\\n  return ret\\n ret[\\'dest\\'] = fnd[\\'rel\\']\\n gzip = load.get(\\'gzip\\', None)\\n with salt.utils.fopen(os.path.normpath(fnd[\\'path\\']), \\'rb\\') as fp_:\\n  fp_.seek(load[\\'loc\\'])\\n  data = fp_.read(__opts__[\\'file_buffer_size\\'])\\n  if (gzip and data):\\n   data = salt.utils.gzip_util.compress(data, gzip)\\n   ret[\\'gzip\\'] = gzip\\n  ret[\\'data\\'] = data\\n return ret\\n',\n  'predictions': ['return a chunk from a file based on the data received .'],\n  'references': ['return a chunk from a file based on the data received .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 80,\n  'code': 'def skip(reason):\\n def decorator(test_item):\\n  if (not isinstance(test_item, (type, types.ClassType))):\\n   @functools.wraps(test_item)\\n   def skip_wrapper(*args, **kwargs):\\n    raise SkipTest(reason)\\n   test_item = skip_wrapper\\n  test_item.__unittest_skip__ = True\\n  test_item.__unittest_skip_why__ = reason\\n  return test_item\\n return decorator\\n',\n  'predictions': ['unconditionally skip a test .'],\n  'references': ['unconditionally skip a test .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 81,\n  'code': 'def setup_platform(hass, config, add_devices, discovery_info=None):\\n devs = config.get(CONF_DEVICES)\\n add_devices([MochadSwitch(hass, mochad.CONTROLLER.ctrl, dev) for dev in devs])\\n return True\\n',\n  'predictions': ['setup the zigbee switch platform .'],\n  'references': ['setup x10 switches over a mochad controller .'],\n  'bleu': 0.17516432701748888,\n  'rouge_l': 0.2785388127853881},\n {'id': 82,\n  'code': \"def test_boolean():\\n assert hug.types.boolean('1')\\n assert hug.types.boolean('T')\\n assert (not hug.types.boolean(''))\\n assert hug.types.boolean('False')\\n assert (not hug.types.boolean(False))\\n\",\n  'predictions': ['test to ensure that the boolean type correctly handles a hug type .'],\n  'references': ['test to ensure the custom boolean type correctly supports boolean conversion .'],\n  'bleu': 0.2737928561916526,\n  'rouge_l': 0.6446499339498017},\n {'id': 83,\n  'code': \"def jet():\\n rc('image', cmap='jet')\\n im = gci()\\n if (im is not None):\\n  im.set_cmap(cm.jet)\\n draw_if_interactive()\\n\",\n  'predictions': ['set the default colormap to jet and apply to current image if any .'],\n  'references': ['set the default colormap to jet and apply to current image if any .'],\n  'bleu': 1.0,\n  'rouge_l': 1.0},\n {'id': 84,\n  'code': 'def pperm(accessing_obj, accessed_obj, *args, **kwargs):\\n return perm(_to_player(accessing_obj), accessed_obj, *args, **kwargs)\\n',\n  'predictions': ['only allow objects .'],\n  'references': ['the basic permission-checker only for player objects .'],\n  'bleu': 0.18693159143202892,\n  'rouge_l': 0.47164948453608246},\n {'id': 85,\n  'code': 'def unregister_hosting_service(name):\\n try:\\n  _hosting_service_registry.unregister_by_attr(u\\'hosting_service_id\\', name)\\n except ItemLookupError as e:\\n  logging.error((u\\'Failed to unregister unknown hosting service \"%s\"\\' % name))\\n  raise e\\n',\n  'predictions': ['unregister the hosting service .'],\n  'references': ['unregister a previously registered hosting service .'],\n  'bleu': 0.36015288308423526,\n  'rouge_l': 0.6472148541114059},\n {'id': 86,\n  'code': \"def reconn_notice():\\n guide = ((light_magenta('You can use ') + light_green('switch')) + light_magenta(' command to return to your stream.\\\\n'))\\n guide += ((light_magenta('Type ') + light_green('h stream')) + light_magenta(' for more details.'))\\n printNicely(guide)\\n sys.stdout.write(g['decorated_name'](g['PREFIX']))\\n sys.stdout.flush()\\n\",\n  'predictions': ['displays out reconn notice .'],\n  'references': ['notice when hangup or timeout .'],\n  'bleu': 0.24736929544091937,\n  'rouge_l': 0.3577712609970674},\n {'id': 87,\n  'code': 'def runproc(cmd):\\n proc = Popen([cmd], shell=True, stdin=PIPE, stdout=PIPE, stderr=PIPE, close_fds=True)\\n (stdoutdata, stderrdata) = proc.communicate()\\n return (stdoutdata, stderrdata)\\n',\n  'predictions': ['look up zero .'],\n  'references': ['convenience method for executing operating system commands .'],\n  'bleu': 0.13218059591958078,\n  'rouge_l': 0.15721649484536082},\n {'id': 88,\n  'code': \"def convert_unreachable_exception(e, error_format=u'Facebook is unreachable %s'):\\n exception_class = map_unreachable_exception(e)\\n error_message = (error_format % str(e))\\n exception = exception_class(error_message)\\n return exception\\n\",\n  'predictions': ['converts a server-side exception below the correct script_name .'],\n  'references': ['converts an sslerror .'],\n  'bleu': 0.15619699684601276,\n  'rouge_l': 0.3306233062330623},\n {'id': 89,\n  'code': 'def init_pool_worker():\\n signal.signal(signal.SIGINT, signal.SIG_IGN)\\n',\n  'predictions': ['init the pool .'],\n  'references': ['make every worker ignore keyboarinterrups since it will be handled by the parent process .'],\n  'bleu': 0.025419978385188596,\n  'rouge_l': 0.190625},\n {'id': 90,\n  'code': 'def output(data, **kwargs):\\n return salt.utils.locales.sdecode(str(data))\\n',\n  'predictions': ['mane function .'],\n  'references': ['rather basic .'],\n  'bleu': 0.537284965911771,\n  'rouge_l': 0.3333333333333333},\n {'id': 91,\n  'code': \"def count_ngrams(text, max_ngram_size, stop_words):\\n if (not isinstance(stop_words, set)):\\n  stop_words = set(stop_words)\\n words = [word.lower() for word in WORD_RE.findall(text) if (word.lower() not in stop_words)]\\n ngram_counts = defaultdict(int)\\n for i in range(len(words)):\\n  for n in range(1, (max_ngram_size + 1)):\\n   if ((i + n) <= len(words)):\\n    ngram = ' '.join(words[i:(i + n)])\\n    ngram_counts[(n, ngram)] += 1\\n for n in range(1, (max_ngram_size + 1)):\\n  ngram_counts[(n, None)] = ((len(words) - n) + 1)\\n return ngram_counts\\n\",\n  'predictions': ['takes a number of ngrams separated in a string .'],\n  'references': ['break text down into ngrams .'],\n  'bleu': 0.13950796967929133,\n  'rouge_l': 0.26180257510729615},\n {'id': 92,\n  'code': 'def filepath_to_uri(path):\\n if (path is None):\\n  return path\\n return urllib.quote(smart_str(path).replace(\\'\\\\\\\\\\', \\'/\\'), safe=\"/~!*()\\'\")\\n',\n  'predictions': ['convert a file system path to a uri portion that is suitable for inclusion in a url .'],\n  'references': ['convert an file system path to a uri portion that is suitable for inclusion in a url .'],\n  'bleu': 0.8979542144404234,\n  'rouge_l': 0.9444444444444445},\n {'id': 93,\n  'code': \"def FormatCode(unformatted_source, filename='<unknown>', style_config=None, lines=None, print_diff=False, verify=False):\\n _CheckPythonVersion()\\n style.SetGlobalStyle(style.CreateStyleFromConfig(style_config))\\n if (not unformatted_source.endswith('\\\\n')):\\n  unformatted_source += '\\\\n'\\n tree = pytree_utils.ParseCodeToTree(unformatted_source)\\n comment_splicer.SpliceComments(tree)\\n continuation_splicer.SpliceContinuations(tree)\\n subtype_assigner.AssignSubtypes(tree)\\n split_penalty.ComputeSplitPenalties(tree)\\n blank_line_calculator.CalculateBlankLines(tree)\\n uwlines = pytree_unwrapper.UnwrapPyTree(tree)\\n for uwl in uwlines:\\n  uwl.CalculateFormattingInformation()\\n _MarkLinesToFormat(uwlines, lines)\\n reformatted_source = reformatter.Reformat(uwlines, verify)\\n if (unformatted_source == reformatted_source):\\n  return (('' if print_diff else reformatted_source), False)\\n code_diff = _GetUnifiedDiff(unformatted_source, reformatted_source, filename=filename)\\n if print_diff:\\n  return (code_diff, (code_diff != ''))\\n return (reformatted_source, True)\\n\",\n  'predictions': ['format the code between two python source files .'],\n  'references': ['format a string of python code .'],\n  'bleu': 0.17747405280050263,\n  'rouge_l': 0.38364779874213834},\n {'id': 94,\n  'code': \"@step('I will confirm all alerts')\\ndef i_confirm_all_alerts(step):\\n world.browser.execute_script('window.confirm = function(){return true;} ; window.alert = function(){return;}')\\n\",\n  'predictions': ['confirm that a step window in a step .'],\n  'references': ['please note: this method must be called right before an expected alert window variables are page local and thus all changes are removed upon navigating to a new page in'],\n  'bleu': 0.016276220793949598,\n  'rouge_l': 0.09348659003831418},\n {'id': 95,\n  'code': 'def get_text(original, token, replace):\\n if replace:\\n  return token.text\\n else:\\n  return original[token.startchar:token.endchar]\\n',\n  'predictions': ['use the build non text .'],\n  'references': ['convenience function for getting the text to use for a match when formatting .'],\n  'bleu': 0.07321724281412775,\n  'rouge_l': 0.2798165137614679},\n {'id': 96,\n  'code': 'def test_ranking_ignores_identifier_quotes(completer):\\n text = u\\'user\\'\\n collection = [u\\'user_action\\', u\\'\"user\"\\']\\n matches = completer.find_matches(text, collection)\\n assert (len(matches) == 2)\\n',\n  'predictions': ['make sure that the ignores of different matches the ignores .'],\n  'references': ['when calculating result rank .'],\n  'bleu': 0.11390778025531027,\n  'rouge_l': 0.13406593406593406},\n {'id': 97,\n  'code': 'def temp_file_for(path):\\n ext = os.path.splitext(path)[1]\\n with NamedTemporaryFile(suffix=ext, delete=False) as f:\\n  return f.name\\n',\n  'predictions': ['returns temp file for a given path .'],\n  'references': ['return an unused filename with the same extension as the specified path .'],\n  'bleu': 0.11296874775996037,\n  'rouge_l': 0.18263473053892215},\n {'id': 98,\n  'code': \"def token_urlsafe(nbytes=None):\\n tok = token_bytes(nbytes)\\n return base64.urlsafe_b64encode(tok).rstrip('=').decode('ascii')\\n\",\n  'predictions': ['base64 decodes a string .'],\n  'references': ['return a random url-safe text string .'],\n  'bleu': 0.25880882365505126,\n  'rouge_l': 0.48541114058355433},\n {'id': 99,\n  'code': \"def setup_logger(logger, stream, filename=None, fmt=None):\\n if (len(logger.handlers) < 1):\\n  console = logging.StreamHandler(stream)\\n  console.setLevel(logging.DEBUG)\\n  console.setFormatter(logging.Formatter(fmt))\\n  logger.addHandler(console)\\n  logger.setLevel(logging.DEBUG)\\n  if filename:\\n   outfile = logging.FileHandler(filename)\\n   outfile.setLevel(logging.INFO)\\n   outfile.setFormatter(logging.Formatter(('%(asctime)s ' + (fmt if fmt else '%(message)s'))))\\n   logger.addHandler(outfile)\\n\",\n  'predictions': ['setup logger for runserver .'],\n  'references': ['sets up a logger for console output .'],\n  'bleu': 0.2118947430943267,\n  'rouge_l': 0.44309927360774815}]"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T12:29:48.575410Z",
     "start_time": "2024-07-18T12:29:48.570953Z"
    }
   },
   "id": "14e2f9c5617afd61"
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "my_dict = {'bleu':[], 'rouge':[], 'meteor':[]}\n",
    "for data in my:\n",
    "    my_dict['bleu'].append(100*data['bleu'])\n",
    "    my_dict['rouge'].append(100*data['rouge_l'])\n",
    "    p = [w for w in data['predictions'][0].split()]\n",
    "    r = [w for w in data['references'][0].split()]\n",
    "    res = round(meteor_score([r], p), 4)*100\n",
    "    my_dict['meteor'].append(res)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T12:29:50.866402Z",
     "start_time": "2024-07-18T12:29:50.865087Z"
    }
   },
   "id": "f45c5f19270ffe00"
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36.71950405317906\n",
      "49.45123060453071\n",
      "43.1224\n"
     ]
    }
   ],
   "source": [
    "print(sum(my_dict['bleu'])/100)\n",
    "print(sum(my_dict['rouge'])/100)\n",
    "print(sum(my_dict['meteor'])/100)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T12:29:52.012535Z",
     "start_time": "2024-07-18T12:29:52.006315Z"
    }
   },
   "id": "f96cd84cd3c3a1e2"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "cebbfcce2a153aa4"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "6860da753c33a190"
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [],
   "source": [
    "with open('./' + 'result_my.json', 'w') as save_file:\n",
    "    json.dump(my_dict, save_file, indent=2, separators=(',', ':'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T12:29:55.163835Z",
     "start_time": "2024-07-18T12:29:55.157204Z"
    }
   },
   "id": "b528b5074dad942d"
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "def self_score(file, res_dict):\n",
    "    gpt_pred = json.load(open(file, 'r'))\n",
    "    rg = Rouge()\n",
    "    _, bleu, ind_bleu = corpus_bleu(gpt_pred, res_dict)\n",
    "    b = [t*100 for t in list(ind_bleu.values())]\n",
    "    average_score, r = rg.compute_score(gpt_pred, res_dict)\n",
    "    rp = [t*100 for t in list(r.values())]\n",
    "    meteor = []\n",
    "    for j in range(100):\n",
    "        t = \"{}\".format(j)\n",
    "        p = [w for w in gpt_pred[t][0].split()]\n",
    "        r = [w for w in res_dict[t][0].split()]\n",
    "        res = round(meteor_score([r], p), 4)*100\n",
    "        meteor.append(res)\n",
    "    return {'bleu':b,'rouge':rp,'meteor':meteor}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-31T04:14:00.284267Z",
     "start_time": "2024-07-31T04:14:00.271185Z"
    }
   },
   "id": "41c9b1b58a18fb38"
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "file = './gpt4opr.json'\n",
    "with open('./' + 'result4opr.json', 'w') as save_file:\n",
    "    json.dump(self_score(file, res_dict), save_file, indent=2, separators=(',', ':'))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T12:32:31.431308Z",
     "start_time": "2024-07-18T12:32:31.401444Z"
    }
   },
   "id": "1e4bc8b20cbe88c9"
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [
    {
     "data": {
      "text/plain": "{'bleu': [7.832899330004498,\n  6.3848752955077925,\n  6.667489966054594,\n  23.24522441081612,\n  9.562406574442013,\n  6.024757292375468,\n  21.16253761537182,\n  9.449865252803164,\n  5.066196809932206,\n  13.217947626377288,\n  13.61294711534851,\n  10.571070857151538,\n  8.097785064266201,\n  7.692375026049747,\n  9.560408787521254,\n  13.400825781778893,\n  13.566979610140004,\n  25.748661016289674,\n  7.6584122760410045,\n  3.9922049256410985,\n  17.827531042796256,\n  9.78237574896145,\n  8.225964699966553,\n  9.083627868206415,\n  6.439931429457923,\n  7.65635970878477,\n  13.439944609633619,\n  10.079037376973918,\n  19.96019880774733,\n  26.760322756637912,\n  14.85237584394808,\n  14.991106946711685,\n  18.207052811092137,\n  35.27295712700594,\n  8.513012360883545,\n  9.147827112247601,\n  12.605968092174912,\n  8.756189878973519,\n  11.390778025531027,\n  47.54373049371216,\n  9.629943614188138,\n  6.900297641435706,\n  17.03318603763928,\n  15.619699684601276,\n  20.556680845025983,\n  4.858527134479512,\n  33.18077402843942,\n  8.839374326825924,\n  13.107175678306445,\n  13.950796967929133,\n  10.571070857151538,\n  9.525245831601728,\n  9.78237574896145,\n  11.35935489027116,\n  18.798317647335086,\n  11.390778025531027,\n  11.498759556447222,\n  16.108992769687397,\n  10.298326000817957,\n  12.605968092174912,\n  11.390778025531027,\n  28.751742289713444,\n  9.78237574896145,\n  6.735938555336447,\n  14.576846149722611,\n  17.996531271765896,\n  9.55204080682377,\n  11.498759556447222,\n  14.694106251955755,\n  20.556680845025983,\n  6.555660318294844,\n  17.566293990351504,\n  11.640435130573177,\n  11.12176984362864,\n  11.35935489027116,\n  16.784459625186194,\n  7.977026311224286,\n  1.4210868968260837,\n  14.283632578659287,\n  39.553325358771794,\n  17.395797375642235,\n  11.498759556447222,\n  11.192003885776355,\n  14.306067650066016,\n  13.54599427337814,\n  17.03318603763928,\n  10.390302174233558,\n  8.225964699966553,\n  12.605968092174912,\n  9.614217984757346,\n  14.113991930789776,\n  8.225964699966553,\n  13.919212131108496,\n  11.498759556447222,\n  2.0077204398364095,\n  11.12176984362864,\n  16.036590969929357,\n  47.85543921093738,\n  12.605968092174912,\n  18.207052811092137],\n 'rouge': [20.515695067264573,\n  19.741100323624597,\n  15.721649484536082,\n  34.014869888475836,\n  23.80487804878049,\n  18.503538928210315,\n  35.67251461988303,\n  35.49951503394762,\n  6.327800829875518,\n  31.322207958921695,\n  32.972972972972975,\n  19.741100323624597,\n  26.842684268426844,\n  8.40220385674931,\n  20.0,\n  30.576441102756885,\n  39.1025641025641,\n  40.45092838196286,\n  16.501352569882776,\n  19.426751592356688,\n  53.41506129597198,\n  16.180371352785148,\n  9.91869918699187,\n  22.536945812807883,\n  6.710671067106711,\n  16.05263157894737,\n  30.550918196994992,\n  26.12419700214133,\n  40.75723830734967,\n  46.983311938382535,\n  34.014869888475836,\n  20.0,\n  40.45092838196286,\n  64.02671755725191,\n  14.769975786924942,\n  20.89041095890411,\n  12.577319587628866,\n  26.24784853700517,\n  12.951167728237788,\n  68.02973977695167,\n  24.18235877106045,\n  24.432576769025367,\n  44.68864468864468,\n  22.22222222222222,\n  34.6590909090909,\n  35.39651837524178,\n  47.21362229102167,\n  7.587064676616915,\n  32.50444049733569,\n  23.92156862745098,\n  20.573355817875214,\n  19.122257053291534,\n  22.453987730061346,\n  23.076923076923084,\n  37.947122861586315,\n  12.298387096774194,\n  17.256011315417258,\n  28.328173374613,\n  21.70818505338078,\n  14.022988505747128,\n  12.298387096774194,\n  63.941299790356396,\n  16.180371352785148,\n  22.592592592592588,\n  32.17299578059071,\n  43.14002828854314,\n  9.131736526946108,\n  20.962199312714777,\n  34.3984962406015,\n  32.360742705570296,\n  19.45773524720893,\n  48.865153538050734,\n  29.82885085574572,\n  29.82885085574572,\n  24.629878869448184,\n  34.9236641221374,\n  26.180257510729614,\n  15.813350615683733,\n  41.14671163575043,\n  50.0,\n  38.79173290937997,\n  19.303797468354432,\n  19.551282051282048,\n  46.80306905370844,\n  30.70469798657718,\n  42.73204903677758,\n  10.481099656357388,\n  8.243243243243244,\n  24.596774193548388,\n  33.197278911564624,\n  15.288220551378442,\n  8.840579710144928,\n  33.22440087145969,\n  20.098846787479406,\n  15.301003344481606,\n  22.371638141809292,\n  14.769975786924942,\n  61.53846153846153,\n  21.36602451838879,\n  43.32386363636363],\n 'meteor': [25.86,\n  39.7,\n  22.73,\n  45.51,\n  35.709999999999994,\n  21.740000000000002,\n  35.46,\n  39.97,\n  8.33,\n  37.730000000000004,\n  42.76,\n  38.14,\n  51.11,\n  7.140000000000001,\n  28.62,\n  61.94,\n  48.559999999999995,\n  54.09,\n  11.63,\n  9.2,\n  69.07,\n  19.23,\n  23.810000000000002,\n  28.09,\n  15.0,\n  6.49,\n  13.889999999999999,\n  39.12,\n  47.33,\n  56.169999999999995,\n  32.21,\n  15.0,\n  42.88,\n  87.89,\n  9.43,\n  34.39,\n  9.09,\n  26.63,\n  26.32,\n  60.089999999999996,\n  14.71,\n  39.18,\n  48.559999999999995,\n  16.669999999999998,\n  23.26,\n  26.11,\n  42.22,\n  4.42,\n  14.02,\n  15.620000000000001,\n  25.86,\n  14.93,\n  17.54,\n  11.540000000000001,\n  49.34,\n  10.639999999999999,\n  13.51,\n  25.3,\n  13.51,\n  27.029999999999998,\n  10.639999999999999,\n  58.08,\n  14.42,\n  14.530000000000001,\n  38.06,\n  50.68,\n  23.53,\n  22.73,\n  53.239999999999995,\n  19.23,\n  7.04,\n  39.18,\n  21.58,\n  14.39,\n  17.86,\n  18.52,\n  22.21,\n  6.25,\n  64.14,\n  49.07,\n  33.900000000000006,\n  11.899999999999999,\n  12.82,\n  38.550000000000004,\n  45.18,\n  60.27,\n  7.580000000000001,\n  11.49,\n  54.37,\n  17.24,\n  13.889999999999999,\n  14.49,\n  27.41,\n  20.0,\n  6.69,\n  17.990000000000002,\n  18.87,\n  67.95,\n  20.27,\n  65.41]}"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self_score('./gpt4o.json', res_dict)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-07-18T12:31:11.964452Z",
     "start_time": "2024-07-18T12:31:11.909719Z"
    }
   },
   "id": "6aba496cbfd2e535"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9741363204a34e96"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
